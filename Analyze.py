import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, time, timedelta
import io
import matplotlib.pyplot as plt
import matplotlib
from datetime import datetime as dt
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.font_manager as fm
import urllib.request
import os

# 1.1 à¸£à¸°à¸šà¸šà¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”à¹à¸¥à¸°à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¸Ÿà¸­à¸™à¸•à¹Œà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
def setup_thai_font():
    font_url = "https://github.com/google/fonts/raw/main/ofl/sarabun/Sarabun-Regular.ttf"
    font_name = "Sarabun-Regular.ttf"
    try:
        if not os.path.exists(font_name):
            urllib.request.urlretrieve(font_url, font_name)
        fm.fontManager.addfont(font_name)
        # à¸”à¸¶à¸‡à¸Šà¸·à¹ˆà¸­à¸Ÿà¸­à¸™à¸•à¹Œà¸—à¸µà¹ˆà¹à¸—à¹‰à¸ˆà¸£à¸´à¸‡à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ
        prop = fm.FontProperties(fname=font_name)
        return prop
    except Exception as e:
        st.error(f"Font Load Error: {e}")
        return None

# à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹à¸¥à¸°à¹€à¸à¹‡à¸šà¸•à¸±à¸§à¹à¸›à¸£à¹„à¸§à¹‰à¹ƒà¸Šà¹‰à¸—à¸±à¹ˆà¸§à¹‚à¸›à¸£à¹à¸à¸£à¸¡
thai_font_prop = setup_thai_font()

if thai_font_prop:
    # à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Default à¹ƒà¸«à¹‰ Matplotlib à¹ƒà¸Šà¹‰à¸Ÿà¸­à¸™à¸•à¹Œà¸—à¸µà¹ˆà¹‚à¸«à¸¥à¸”à¸¡à¸²
    matplotlib.rcParams['font.family'] = thai_font_prop.get_name()
else:
    # à¸à¸£à¸“à¸µà¹‚à¸«à¸¥à¸”à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆà¸ˆà¸£à¸´à¸‡à¹† à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸Ÿà¸­à¸™à¸•à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¹ƒà¸™à¸£à¸°à¸šà¸š
    matplotlib.rcParams['font.family'] = 'sans-serif'

#=============================================================================

def apply_calc_logic(df):
    """à¸£à¸±à¸à¸©à¸² Logic à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¹€à¸”à¸´à¸¡: à¸ªà¸£à¹‰à¸²à¸‡ flag à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸¸à¸“à¸ à¸²à¸ž"""
    pm_cols = [c for c in df.columns if 'PM' in c]
    pc_cols = [c for c in df.columns if 'PC' in c]
    piera_cols = pm_cols + pc_cols
    dht_cols = ['humidity', 'temperature']
    
    df['has_dht'] = df[[c for c in dht_cols if c in df.columns]].notnull().all(axis=1) if any(c in df.columns for c in dht_cols) else False
    df['has_piera'] = df[[c for c in piera_cols if c in df.columns]].notnull().any(axis=1) if piera_cols else False
    df['has_both'] = df['has_dht'] & df['has_piera']
    return df

def process_file(file):
    """à¸ªà¸£à¹‰à¸²à¸‡ Dataset à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œà¹€à¸žà¸µà¸¢à¸‡à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸”à¸µà¸¢à¸§ à¹‚à¸”à¸¢à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸¸à¸à¸§à¸±à¸™à¸—à¸µà¹ˆà¸¡à¸µ"""
    try:
        df = pd.read_csv(file)
        df['datetime'] = pd.to_datetime(df['datetime'], format='%d-%m-%Y-%H-%M-%S')
        df = df.sort_values('datetime')
        
        points_data = {}
        if 'point_id' in df.columns:
            for pid in df['point_id'].unique():
                pdf = df[df['point_id'] == pid].copy()
                sensor_cols = [c for c in pdf.columns if c not in ['datetime', 'point_id']]
                pdf = pdf.dropna(subset=sensor_cols, how='all')
                points_data[str(pid)] = apply_calc_logic(pdf)
        else:
            suffixes = set([c.split('_')[-1] for c in df.columns if '_P' in c])
            for s in sorted(suffixes):
                p_cols = [c for c in df.columns if c.endswith(f'_{s}')]
                pdf = df[['datetime'] + p_cols].copy()
                pdf.columns = ['datetime'] + [c.replace(f'_{s}', '') for c in p_cols]
                sensor_cols = [c for c in pdf.columns if c != 'datetime']
                pdf = pdf.dropna(subset=sensor_cols, how='all')
                points_data[s] = apply_calc_logic(pdf)

        if not points_data:
            return None, "à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Point à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œ"

        return {"raw_df": df, "points_data": points_data}, "Success"
    except Exception as e:
        return None, f"Error: {str(e)}"

def calculate_stats(df):
    """à¸„à¸³à¸™à¸§à¸“à¸ªà¸–à¸´à¸•à¸´à¸„à¸¸à¸“à¸ à¸²à¸žà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (Logic à¹€à¸”à¸´à¸¡)"""
    SEC_PER_DAY = 86400
    MIN_PER_DAY = 1440
    def get_metrics(mask):
        count = mask.sum()
        avg_min = count / MIN_PER_DAY
        pct = (count / SEC_PER_DAY) * 100
        missing = SEC_PER_DAY - count
        return [count, avg_min, pct, max(0, missing)]
    
    overall = get_metrics(pd.Series([True] * len(df)))
    dht = get_metrics(df['has_dht'])
    piera = get_metrics(df['has_piera'])
    both = get_metrics(df['has_both'])
    
    return pd.DataFrame({
        'Metric': ['Total Seconds', 'Avg per Minute', '% of Day', 'Missing Seconds'],
        'Overall': overall, 'DHT22': dht, 'Piera': piera, 'Both Sensors': both
    }).set_index('Metric')

# --- 2. à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸šà¹ƒà¸«à¸¡à¹ˆ (Summary Report Only) ---

def calculate_continuity_v3(df, start_ts, end_ts, expected_sec):
    """à¸„à¸³à¸™à¸§à¸“à¸ªà¸–à¸´à¸•à¸´à¹à¸¢à¸à¸›à¸£à¸°à¹€à¸ à¸— à¸žà¸£à¹‰à¸­à¸¡ Overall à¹à¸¥à¸° Outlier"""
    mask = (df['datetime'] >= start_ts) & (df['datetime'] <= end_ts)
    df_filtered = df.loc[mask].copy()
    
    if df_filtered.empty:
        return None, None

    # 1. Overall: à¸ˆà¸³à¸™à¸§à¸™à¸§à¸´à¸™à¸²à¸—à¸µà¸—à¸µà¹ˆà¸¡à¸µà¹à¸–à¸§à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸—à¸³à¸‡à¸²à¸™)
    overall_count = len(df_filtered)
    
    # 2. à¹à¸¢à¸à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸‹à¸™à¹€à¸‹à¸­à¸£à¹Œ (à¸§à¸´à¸™à¸²à¸—à¸µà¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥)
    dht_count = df_filtered['has_dht'].sum()
    piera_count = df_filtered['has_piera'].sum()
    both_count = df_filtered['has_both'].sum()

    # 3. Outlier (> 6600)
    outlier_count = 0
    if 'PM2_5' in df_filtered.columns:
        outlier_count = len(df_filtered[df_filtered['PM2_5'] > 6600])

    stats = {
        'overall': {'sec': overall_count, 'pct': (overall_count / expected_sec) * 100},
        'dht': {'sec': dht_count, 'pct': (dht_count / expected_sec) * 100},
        'piera': {'sec': piera_count, 'pct': (piera_count / expected_sec) * 100},
        'both': {'sec': both_count, 'pct': (both_count / expected_sec) * 100},
        'outlier': outlier_count
    }
    
    # 4. Resample 5min à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸£à¸²à¸Ÿ
    resampled_graph = df_filtered.set_index("datetime").resample("5min").count()
    
    return stats, resampled_graph

def generate_summary_report(points_data, target_date_str, report_type, export_format, manual_text=None):
    # à¸”à¸¶à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸ˆà¸²à¸ Dataset
    first_df = list(points_data.values())[0]
    base_date = first_df['datetime'].dt.normalize().iloc[0]
    
    start_dt = base_date
    if report_type == "12 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡":
        end_dt = base_date + timedelta(hours=11, minutes=59, seconds=59)
        total_sec = 43200
    else:
        end_dt = base_date + timedelta(hours=23, minutes=59, seconds=59)
        total_sec = 86400

    # --- à¸ªà¹ˆà¸§à¸™à¸•à¸£à¸£à¸à¸°à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ ---
    # à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸ªà¹ˆà¸‡ manual_text à¸¡à¸² (à¸„à¸·à¸­à¸à¸²à¸£à¸à¸”à¸„à¸³à¸™à¸§à¸“à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸) à¹ƒà¸«à¹‰à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
    if manual_text is None:
        report_text = f"à¸£à¸²à¸¢à¸‡à¸²à¸™à¸œà¸¥à¸§à¸±à¸™à¸—à¸µà¹ˆ {base_date.strftime('%d/%m/%Y')}\n"
        report_text += f"à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¡à¸² {report_type}\n"
        report_text += f"à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸‚à¹‰à¸²à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸° Point à¸ˆà¸²à¸à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” {total_sec} à¸§à¸´à¸™à¸²à¸—à¸µ\n\n"

        point_details = ""
        for pid, df in points_data.items():
            stats, _ = calculate_continuity_v3(df, start_dt, end_dt, total_sec)
            if stats:
                point_details += f"P{pid}:\n"
                point_details += f"à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‚à¹‰à¸² (Overall): {stats['overall']['sec']} à¸§à¸´à¸™à¸²à¸—à¸µ ({stats['overall']['pct']:.2f}%)\n"
                point_details += f"- DHT22: {stats['dht']['sec']} à¸§à¸´à¸™à¸²à¸—à¸µ ({stats['dht']['pct']:.2f}%)\n"
                point_details += f"- Piera: {stats['piera']['sec']} à¸§à¸´à¸™à¸²à¸—à¸µ ({stats['piera']['pct']:.2f}%)\n"
                point_details += f"- à¸—à¸±à¹‰à¸‡à¸„à¸¹à¹ˆ (Both): {stats['both']['sec']} à¸§à¸´à¸™à¸²à¸—à¸µ ({stats['both']['pct']:.2f}%)\n"
                point_details += f"Outlier à¸—à¸µà¹ˆà¸žà¸š: {stats['outlier']} à¸„à¹ˆà¸²\n\n"
        
        final_display_text = report_text + point_details
    else:
        # à¸–à¹‰à¸²à¸¡à¸µ manual_text (à¸ªà¹ˆà¸‡à¸¡à¸²à¸ˆà¸²à¸ text_area) à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸™à¸±à¹‰à¸™à¸§à¸²à¸”à¸¥à¸‡à¸£à¸¹à¸›à¹€à¸¥à¸¢
        final_display_text = manual_text

    # --- à¸ªà¹ˆà¸§à¸™à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸¹à¸›à¸ à¸²à¸ž ---
    plt.close('all')
    fig = plt.figure(figsize=(10, 14))
    ax_text = fig.add_axes([0.1, 0.40, 0.8, 0.55]) 
    ax_text.axis('off')
    ax_graph = fig.add_axes([0.1, 0.1, 0.8, 0.25])

    # à¸§à¸²à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ (à¹ƒà¸Šà¹‰ final_display_text)
    ax_text.text(0, 1, final_display_text, 
                 fontproperties=thai_font_prop, 
                 fontsize=11, 
                 verticalalignment='top', 
                 linespacing=1.4)

    # à¸§à¸²à¸”à¸à¸£à¸²à¸Ÿ
    for pid, df in points_data.items():
        _, res_graph = calculate_continuity_v3(df, start_dt, end_dt, total_sec)
        if res_graph is not None:
            ax_graph.plot(res_graph.index, res_graph['has_both'], label=f'Point {pid}', linewidth=1.5)

    ax_graph.set_title("Data Continuity Trend (Resampled 5 min)")
    ax_graph.set_ylabel("Counts per 5 min")
    ax_graph.legend(loc='upper right')
    ax_graph.grid(True, linestyle='--', alpha=0.5)
    plt.xticks(rotation=45)

    # Export Logic
    files = {}
    if export_format != "None": # à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚à¸à¸£à¸“à¸µà¸­à¸¢à¸²à¸à¹„à¸”à¹‰à¹à¸„à¹ˆ Text à¹„à¸¡à¹ˆà¹€à¸­à¸²à¹„à¸Ÿà¸¥à¹Œ
        if export_format in ["PNG", "à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¹à¸šà¸š"]:
            buf = io.BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight', dpi=150)
            files['png'] = buf.getvalue()
        if export_format in ["PDF", "à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¹à¸šà¸š"]:
            buf = io.BytesIO()
            with PdfPages(buf) as pdf: pdf.savefig(fig, bbox_inches='tight')
            files['pdf'] = buf.getvalue()
        
    return final_display_text, files
# --- 3. UI State Management ---
if 'analysis_sets' not in st.session_state: st.session_state.analysis_sets = {}
if 'selected_set_id' not in st.session_state: st.session_state.selected_set_id = None
if 'show_summary' not in st.session_state: st.session_state.show_summary = False

st.set_page_config(page_title="Sensor Quality Analysis Dashboard", layout="wide")




# --- 4. Sidebar UI (Logic à¹€à¸”à¸´à¸¡) ---
with st.sidebar:
    st.title("ðŸ›  Management")
    with st.expander("ðŸ†• Create Analysis Set", expanded=not st.session_state.analysis_sets):
        up_file = st.file_uploader("Upload Combined CSV File", type=['csv'])
        
        if st.button("Confirm & Create", use_container_width=True):
            if up_file:
                result, msg = process_file(up_file)
                if result:
                    # à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œà¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸ à¸«à¸²à¸à¸‹à¹‰à¸³à¹ƒà¸«à¹‰à¸•à¹ˆà¸­ Timestamp
                    base_name = up_file.name
                    set_id = base_name
                    if set_id in st.session_state.analysis_sets:
                        set_id = f"{base_name}_{datetime.now().strftime('%H%M%S')}"
                    
                    st.session_state.analysis_sets[set_id] = {
                        'date': base_name, # à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œà¹à¸ªà¸”à¸‡à¸œà¸¥à¹ƒà¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ date à¹€à¸”à¸´à¸¡
                        'file_name': up_file.name,
                        **result 
                    }
                    st.session_state.selected_set_id = set_id
                    st.success(f"à¸ªà¸£à¹‰à¸²à¸‡ Dataset: {set_id} à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")
                    st.rerun()
                else:
                    st.error(msg)
            else:
                st.warning("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ")

    st.markdown("---")
    st.subheader("ðŸ“‚ Saved Analysis Sets")
    for sid, sdata in list(st.session_state.analysis_sets.items()):
        col_select, col_del = st.columns([4, 1])
        # à¹à¸ªà¸”à¸‡à¸Šà¸·à¹ˆà¸­ dataset (à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œ) à¹à¸¥à¸°à¸ˆà¸³à¸™à¸§à¸™ Point
        if col_select.button(f"ðŸ“„ {sid} ({len(sdata['points_data'])} P)", key=f"sel_{sid}", use_container_width=True):
            st.session_state.selected_set_id = sid
        if col_del.button("ðŸ—‘ï¸", key=f"del_{sid}"):
            del st.session_state.analysis_sets[sid]
            if st.session_state.selected_set_id == sid: st.session_state.selected_set_id = None
            st.rerun()

# --- 5. Main Dashboard Area ---
if st.session_state.selected_set_id:
    curr_set = st.session_state.analysis_sets[st.session_state.selected_set_id]
    points_dict = curr_set['points_data']
    target_date = curr_set['date']
    
    # ðŸŽ¯ Header à¸žà¸£à¹‰à¸­à¸¡à¸›à¸¸à¹ˆà¸¡ "à¸ªà¸£à¸¸à¸›à¸œà¸¥"
    h1, h2 = st.columns([8, 2])
    with h1:
        st.title(f"ðŸ“Š Analysis: {target_date}")
    with h2:
        st.write(" ")
        if st.button("ðŸ“Š Summary Report", use_container_width=True, type="primary"):
            st.session_state.show_summary = not st.session_state.show_summary

    # ðŸŽ¯ à¸£à¸°à¸šà¸š Summary Report Overlay
    if st.session_state.show_summary:
        with st.container(border=True):
            st.subheader("ðŸ“ à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸²à¸¢à¸‡à¸²à¸™à¸ªà¸£à¸¸à¸›à¸œà¸¥ (Summary Report)")
            c1, c2 = st.columns(2)
            with c1:
                sel_type = st.radio("à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²", ["12 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡", "24 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡"], horizontal=True)
            with c2:
                sel_format = st.selectbox("à¸£à¸¹à¸›à¹à¸šà¸š Export", ["PNG", "PDF", "à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¹à¸šà¸š"])
            
            # 1. à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹ƒà¸ªà¹ˆ session_state (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ)
            if st.button("âœ… 1. à¸„à¸³à¸™à¸§à¸“à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™", use_container_width=True):
                # à¸”à¸¶à¸‡à¹à¸„à¹ˆà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸à¸±à¸š Graph data (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸—à¸³à¹„à¸Ÿà¸¥à¹Œ PNG)
                report_txt, _ = generate_summary_report(points_dict, target_date, sel_type, "None")
                st.session_state.editable_report = report_txt

            # 2. à¸Šà¹ˆà¸­à¸‡ Text Area à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸à¹‰à¹„à¸‚ (à¸ˆà¸°à¸ˆà¸³à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸žà¸´à¸¡à¸žà¹Œà¹„à¸§à¹‰)
            if 'editable_report' in st.session_state:
                final_text = st.text_area("à¹à¸à¹‰à¹„à¸‚à¸ªà¸£à¸¸à¸›à¸£à¸²à¸¢à¸‡à¸²à¸™à¸à¹ˆà¸­à¸™à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”", 
                                          value=st.session_state.editable_report, 
                                          height=300, 
                                          key="report_editor")
                
                # 3. à¸›à¸¸à¹ˆà¸¡à¸ªà¸³à¸«à¸£à¸±à¸š "à¸šà¸±à¸™à¸—à¸¶à¸à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ" à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¹à¸à¹‰à¹„à¸‚à¹à¸¥à¹‰à¸§
                if st.button("ðŸ–¼ï¸ 2. à¸¢à¸·à¸™à¸¢à¸±à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸™à¸µà¹‰à¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”", use_container_width=True, type="primary"):
                    # à¸ªà¹ˆà¸‡ final_text à¸à¸¥à¸±à¸šà¹„à¸›à¸§à¸²à¸”à¸¥à¸‡à¸šà¸™à¸£à¸¹à¸›à¸ à¸²à¸žà¹ƒà¸«à¸¡à¹ˆ
                    # à¹€à¸£à¸²à¸ˆà¸°à¹€à¸žà¸´à¹ˆà¸¡ parameter 'manual_text' à¹ƒà¸™à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹€à¸”à¸´à¸¡
                    updated_txt, report_files = generate_summary_report(
                        points_dict, target_date, sel_type, sel_format, manual_text=final_text
                    )
                    st.session_state.final_files = report_files
                    st.success("à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸žà¸£à¹‰à¸­à¸¡à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”à¹à¸¥à¹‰à¸§!")

                # 4. à¹à¸ªà¸”à¸‡à¸›à¸¸à¹ˆà¸¡à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸” (à¸–à¹‰à¸²à¹„à¸Ÿà¸¥à¹Œà¸–à¸¹à¸à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§)
                if "final_files" in st.session_state:
                st.write("---")
                files = st.session_state.final_files
                
                # à¸ªà¸£à¹‰à¸²à¸‡ 3 columns à¹€à¸žà¸·à¹ˆà¸­à¸”à¸±à¸™à¸›à¸¸à¹ˆà¸¡à¸¡à¸²à¹„à¸§à¹‰à¸•à¸£à¸‡à¸à¸¥à¸²à¸‡
                col_l, col_mid, col_r = st.columns([1, 2, 1])
                
                with col_mid:
                    if 'png' in files:
                        st.download_button("ðŸ“¥ Download PNG", files['png'], "report.png", "image/png", use_container_width=True)
                    if 'pdf' in files:
                        st.download_button("ðŸ“„ Download PDF", files['pdf'], "report.pdf", "application/pdf", use_container_width=True)

    # --- UI à¹€à¸”à¸´à¸¡ (à¸«à¹‰à¸²à¸¡à¹à¸à¹‰) ---
    tabs = st.tabs(["ðŸ“‹ Executive Summary", "ðŸ” Gap Analysis", "ðŸ“ˆ Trends & Charts"])
    
    with tabs[0]:
        all_stats = {}
        all_outliers = {}
        for pid, pdf in points_dict.items():
            all_stats[pid] = calculate_stats(pdf)
            all_outliers[pid] = pdf[pdf['PM2_5'] > 6600] if 'PM2_5' in pdf.columns else pd.DataFrame()

        m_cols = st.columns(len(points_dict) + 2)
        m_cols[0].metric("Date", str(target_date))
        for idx, pid in enumerate(points_dict.keys()):
            pct = all_stats[pid].loc['% of Day', 'Both Sensors']
            m_cols[idx+1].metric(f"Point {pid} (%)", f"{pct:.2f}%")
        
        with m_cols[-1]:
            st.write("**Outliers Found**")
            o_sub_cols = st.columns(len(points_dict))
            for idx, pid in enumerate(points_dict.keys()):
                count = len(all_outliers[pid])
                o_sub_cols[idx].markdown(f"### {count}\n<small>P{pid}</small>", unsafe_allow_html=True)

        st.divider()
        for pid, pdf in points_dict.items():
            st.subheader(f"ðŸ“ Point {pid}")
            res = all_stats[pid]
            st.dataframe(res.style.format("{:.2f}").background_gradient(cmap='Blues', axis=1), use_container_width=True)
            csv_buf = io.StringIO()
            res.to_csv(csv_buf)
            st.download_button(f"ðŸ“¥ Download Report Point {pid}", csv_buf.getvalue(), f"Analyze_{pid}_{target_date}.csv", key=f"dl_{pid}")

    with tabs[1]:
        gap_threshold = st.number_input("Gap Threshold (à¸§à¸´à¸™à¸²à¸—à¸µ)", min_value=1, value=5)
        g_cols = st.columns(len(points_dict))
        for idx, (pid, pdf) in enumerate(points_dict.items()):
            with g_cols[idx]:
                st.subheader(f"ðŸ” Point {pid}")
                df_gap = pdf.copy()
                df_gap['diff'] = df_gap['datetime'].diff().dt.total_seconds()
                gaps = df_gap[df_gap['diff'] > gap_threshold].sort_values('diff', ascending=False)
                st.metric(f"Total Gaps (P{pid})", len(gaps))
                st.table(gaps[['datetime', 'diff']].head(5).rename(columns={'diff': 'Duration (s)'}))
                with st.expander(f"à¸”à¸¹ Gap à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸‚à¸­à¸‡ {pid}"):
                    st.dataframe(gaps[['datetime', 'diff']].rename(columns={'diff': 'Duration (s)'}), use_container_width=True)
                st.divider()
                out_df = all_outliers[pid]
                st.write(f"ðŸš¨ **Outliers P{pid} (PM2.5 > 6600)**")
                if not out_df.empty:
                    st.dataframe(out_df[['datetime', 'PM2_5']].rename(columns={'PM2_5': 'PM2.5 (Âµg/mÂ³)'}), use_container_width=True)
                else: st.success(f"Point {pid} à¹„à¸¡à¹ˆà¸žà¸š Outlier")

    with tabs[2]:
        st.subheader("ðŸ“ˆ Data Continuity")
        interval = st.selectbox("à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸² Resample", ["1min", "3min", "5min"], index=0)
        fig_trend = go.Figure()
        for pid, pdf in points_dict.items():
            df_min = pdf.set_index('datetime').resample(interval).count()
            fig_trend.add_trace(go.Scatter(x=df_min.index, y=df_min['has_both'], name=f"Point {pid}", mode='lines'))
        st.plotly_chart(fig_trend, use_container_width=True)
        st.divider()
        st.subheader("ðŸ“Š Sensor Viewer")
        selected_points = st.multiselect("à¹€à¸¥à¸·à¸­à¸ Point", list(points_dict.keys()), default=[list(points_dict.keys())[0]])
        metrics = st.multiselect("à¹€à¸¥à¸·à¸­à¸à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£", ["PM2_5", "temperature", "humidity"], default=["PM2_5"])
        show_outlier = st.checkbox("à¹à¸ªà¸”à¸‡ Outlier (PM2.5 > 6600)", value=True)
        fig_val = go.Figure()
        y_values_for_scale = []
        for pid in selected_points:
            sel_df = points_dict[pid]
            for m in metrics:
                if m in sel_df.columns:
                    fig_val.add_trace(go.Scatter(x=sel_df['datetime'], y=sel_df[m], name=f"{m} (P{pid})", mode='lines'))
                    if m == "PM2_5":
                        y_vals = sel_df[m].dropna() if show_outlier else sel_df[sel_df[m] <= 6600][m].dropna()
                        y_values_for_scale.extend(y_vals.values)
        if y_values_for_scale:
            ymin, ymax = min(y_values_for_scale), max(y_values_for_scale)
            padding = (ymax - ymin) * 0.1 if ymax != ymin else 10
            fig_val.update_yaxes(range=[max(0, ymin - padding), ymax + padding])
        st.plotly_chart(fig_val, use_container_width=True)
else:
    st.title("ðŸ‘ˆ à¹‚à¸›à¸£à¸”à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸«à¸£à¸·à¸­à¹€à¸¥à¸·à¸­à¸à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")

    st.info("à¸£à¸°à¸šà¸šà¸ˆà¸°à¹à¸¢à¸ Overall à¹à¸¥à¸° Gap Analysis à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸° Point à¹ƒà¸«à¹‰à¹‚à¸”à¸¢à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´")




